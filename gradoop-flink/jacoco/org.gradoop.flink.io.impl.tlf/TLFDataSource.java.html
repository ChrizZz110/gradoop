<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TLFDataSource.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Gradoop Flink</a> &gt; <a href="index.source.html" class="el_package">org.gradoop.flink.io.impl.tlf</a> &gt; <span class="el_source">TLFDataSource.java</span></div><h1>TLFDataSource.java</h1><pre class="source lang-java linenums">/*
 * Copyright Â© 2014 - 2021 Leipzig University (Database Research Group)
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.gradoop.flink.io.impl.tlf;

import org.apache.flink.api.java.DataSet;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.hadoopcompatibility.HadoopInputs;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.TextInputFormat;
import org.gradoop.flink.io.api.DataSource;
import org.gradoop.flink.io.impl.tlf.functions.Dictionary;
import org.gradoop.flink.io.impl.tlf.functions.DictionaryEntry;
import org.gradoop.flink.io.impl.tlf.functions.EdgeLabelDecoder;
import org.gradoop.flink.io.impl.tlf.functions.GraphTransactionFromText;
import org.gradoop.flink.io.impl.tlf.functions.TLFFileFormat;
import org.gradoop.flink.io.impl.tlf.functions.VertexLabelDecoder;
import org.gradoop.flink.io.impl.tlf.inputformats.TLFInputFormat;
import org.gradoop.flink.model.impl.epgm.GraphCollection;
import org.gradoop.flink.model.impl.epgm.LogicalGraph;
import org.gradoop.flink.model.impl.layouts.transactional.tuples.GraphTransaction;
import org.gradoop.flink.model.impl.operators.combination.ReduceCombination;
import org.gradoop.flink.util.GradoopFlinkConfig;

import java.io.IOException;
import java.util.Map;

/**
 * Creates an EPGM instance from one TLF file. The exact format is
 * documented in
 * {@link TLFFileFormat}.
 */
<span class="pc bpc" id="L47" title="1 of 2 branches missed.">public class TLFDataSource extends TLFBase implements DataSource {</span>

  /**
   * Creates a new data source. Paths can be local (file://) or HDFS (hdfs://).
   *
   * @param tlfPath tlf data file
   * @param config Gradoop Flink configuration
   */
  public TLFDataSource(String tlfPath, GradoopFlinkConfig config) {
<span class="fc" id="L56">    super(tlfPath, &quot;&quot;, &quot;&quot;, config);</span>
<span class="fc" id="L57">  }</span>

  /**
   * Creates a new data source. Paths can be local (file://) or HDFS (hdfs://).
   *
   * @param tlfPath tlf data file
   * @param tlfVertexDictionaryPath tlf vertex dictionary file
   * @param tlfEdgeDictionaryPath tlf edge dictionary file
   * @param config Gradoop Flink configuration
   */
  public TLFDataSource(String tlfPath, String tlfVertexDictionaryPath,
    String tlfEdgeDictionaryPath, GradoopFlinkConfig config) {
<span class="fc" id="L69">    super(tlfPath, tlfVertexDictionaryPath, tlfEdgeDictionaryPath, config);</span>
<span class="fc" id="L70">    ExecutionEnvironment env = config.getExecutionEnvironment();</span>
<span class="pc bpc" id="L71" title="1 of 2 branches missed.">    if (hasVertexDictionary()) {</span>
<span class="fc" id="L72">      DataSet&lt;Map&lt;Integer, String&gt;&gt; dictionary = env.createInput(HadoopInputs.readHadoopFile(</span>
<span class="fc" id="L73">        new TextInputFormat(), LongWritable.class, Text.class, getTLFVertexDictionaryPath()))</span>
<span class="fc bfc" id="L74" title="All 2 branches covered.">          .filter(t -&gt; !t.f1.toString().isEmpty())</span>
<span class="fc" id="L75">          .map(new DictionaryEntry())</span>
<span class="fc" id="L76">          .reduceGroup(new Dictionary());</span>

<span class="fc" id="L78">      setVertexDictionary(dictionary);</span>
    }
<span class="fc bfc" id="L80" title="All 2 branches covered.">    if (hasEdgeDictionary()) {</span>
<span class="fc" id="L81">      DataSet&lt;Map&lt;Integer, String&gt;&gt; dictionary = env.createInput(HadoopInputs.readHadoopFile(</span>
<span class="fc" id="L82">        new TextInputFormat(), LongWritable.class, Text.class, getTLFEdgeDictionaryPath()))</span>
<span class="pc bpc" id="L83" title="1 of 2 branches missed.">          .filter(t -&gt; !t.f1.toString().isEmpty())</span>
<span class="fc" id="L84">          .map(new DictionaryEntry())</span>
<span class="fc" id="L85">          .reduceGroup(new Dictionary());</span>

<span class="fc" id="L87">      setEdgeDictionary(dictionary);</span>
    }
<span class="fc" id="L89">  }</span>

  @Override
  public LogicalGraph getLogicalGraph() throws IOException {
<span class="nc" id="L93">    return getGraphCollection().reduce(new ReduceCombination&lt;&gt;());</span>
  }

  @Override
  public GraphCollection getGraphCollection() throws IOException {
    DataSet&lt;GraphTransaction&gt; transactions;
<span class="fc" id="L99">    ExecutionEnvironment env = getConfig().getExecutionEnvironment();</span>

<span class="fc" id="L101">    DataSet&lt;Tuple2&lt;LongWritable, Text&gt;&gt; input = null;</span>

<span class="fc" id="L103">    input = env.createInput(HadoopInputs.readHadoopFile(</span>
<span class="fc" id="L104">      new TLFInputFormat(), LongWritable.class, Text.class, getTLFPath()));</span>

    // load tlf graphs from file
<span class="pc bpc" id="L107" title="2 of 4 branches missed.">    assert input != null;</span>
<span class="fc" id="L108">    transactions = input.map(new GraphTransactionFromText(getConfig()));</span>

    // map the integer valued labels to strings from dictionary
<span class="fc bfc" id="L111" title="All 2 branches covered.">    if (hasVertexDictionary()) {</span>
<span class="fc" id="L112">      transactions = transactions</span>
<span class="fc" id="L113">        .map(new VertexLabelDecoder())</span>
<span class="fc" id="L114">        .withBroadcastSet(</span>
<span class="fc" id="L115">          getVertexDictionary(), TLFConstants.VERTEX_DICTIONARY);</span>
    }
<span class="fc bfc" id="L117" title="All 2 branches covered.">    if (hasEdgeDictionary()) {</span>
<span class="fc" id="L118">      transactions = transactions</span>
<span class="fc" id="L119">        .map(new EdgeLabelDecoder())</span>
<span class="fc" id="L120">        .withBroadcastSet(</span>
<span class="fc" id="L121">          getEdgeDictionary(), TLFConstants.EDGE_DICTIONARY);</span>
    }
<span class="fc" id="L123">    return getConfig().getGraphCollectionFactory().fromTransactions(transactions);</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.1.201803210924</span></div></body></html>